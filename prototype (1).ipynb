{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTY8r9mW7W-q",
        "outputId": "42a6f0f0-aaed-488b-a626-deb722950a3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_features(folder_path):\n",
        "  import torchvision.models as models\n",
        "  import os\n",
        "  import shutil\n",
        "  import random\n",
        "  import torch\n",
        "  import torchvision.transforms as transforms\n",
        "  import torchvision.models as models\n",
        "  from PIL import Image\n",
        "  model = models.vgg16(pretrained=True)\n",
        "  model.eval()\n",
        "  features=[]\n",
        "  input_image = Image.open(folder_path)\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to fit ResNet input size\n",
        "    transforms.ToTensor(),           # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize image\n",
        "])\n",
        "\n",
        "  input_tensor = transform(input_image)\n",
        "  input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
        "  with torch.no_grad():\n",
        "\n",
        "    features_tensor = model(input_batch)\n",
        "  feature_vector = features_tensor.squeeze().numpy()\n",
        "  features.append(feature_vector)\n",
        "\n",
        "  return features\n"
      ],
      "metadata": {
        "id": "q8lPEQ8f5eYq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loading(model_path):\n",
        "  import joblib\n",
        "  model=joblib.load(model_path)\n",
        "  return model\n",
        "def making_prediction(model):\n",
        "  predict=model.predict(feature)\n",
        "  return predict\n",
        "def checking_pred(predict):\n",
        "  if predict[0]==1:\n",
        "    print(\"Anomaly\")\n",
        "  elif predict[0]==0:\n",
        "    print(\"Normal\")\n",
        "#checking_pred(predict)"
      ],
      "metadata": {
        "id": "udLImyjK5fPw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=model_loading(\"/content/drive/MyDrive/Group_project/prototype.pkl\")\n",
        "image_path=\"/content/drive/MyDrive/Group_project/Anomaly/001.JPG\"\n",
        "feature=extract_features(image_path)\n",
        "x=making_prediction(m)\n",
        "y=checking_pred(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFneTZXN5hz9",
        "outputId": "5a58d47b-950f-4905-ea1c-6184c9f57132"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 63.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomaly\n"
          ]
        }
      ]
    }
  ]
}